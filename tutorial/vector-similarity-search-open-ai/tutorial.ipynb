{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct vector similarity search on Azure OpenAI embeddings using Azure Managed Redis\n",
    "\n",
    "- Tutorial: https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-vector-similarity\n",
    "- Code: https://github.com/Azure-Samples/azure-cache-redis-samples/tree/main/tutorial/vector-similarity-search-open-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "Install the python dependencies required for our application. Using a Python virtual environment is usually a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/clarence/.local/lib/python3.11/site-packages (1.63.0)\n",
      "Collecting num2words\n",
      "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: matplotlib in /home/clarence/.local/lib/python3.11/site-packages (3.10.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pandas in /home/clarence/.local/lib/python3.11/site-packages (2.2.3)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: redis in /home/clarence/.local/lib/python3.11/site-packages (5.2.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /home/clarence/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/clarence/.local/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Collecting docopt>=0.6.2 (from num2words)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/clarence/.local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/clarence/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/clarence/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/clarence/.local/lib/python3.11/site-packages (from tiktoken) (2.32.3)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n",
      "  Downloading langchain_core-0.3.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/clarence/.local/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/clarence/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/clarence/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/clarence/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/clarence/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/clarence/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/clarence/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/clarence/.local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/clarence/.local/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading langchain_core-0.3.46-py3-none-any.whl (417 kB)\n",
      "Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "Downloading narwhals-1.31.0-py3-none-any.whl (313 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=947fd878c22f66a2c9761f915c9a1c0132b56e0ac6375c7b4382dcc18d7fa34b\n",
      "  Stored in directory: /home/clarence/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, zstandard, threadpoolctl, tenacity, scipy, regex, pydantic-core, orjson, num2words, narwhals, jsonpointer, joblib, greenlet, tiktoken, SQLAlchemy, scikit-learn, requests-toolbelt, pydantic, plotly, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.1\n",
      "    Uninstalling pydantic_core-2.18.1:\n",
      "      Successfully uninstalled pydantic_core-2.18.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.0\n",
      "    Uninstalling pydantic-2.7.0:\n",
      "      Successfully uninstalled pydantic-2.7.0\n",
      "Successfully installed SQLAlchemy-2.0.39 docopt-0.6.2 greenlet-3.1.1 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.21 langchain-core-0.3.46 langchain-text-splitters-0.3.7 langsmith-0.3.18 narwhals-1.31.0 num2words-0.5.14 orjson-3.10.15 plotly-6.0.1 pydantic-2.10.6 pydantic-core-2.27.2 regex-2024.11.6 requests-toolbelt-1.0.0 scikit-learn-1.6.1 scipy-1.15.2 tenacity-9.0.0 threadpoolctl-3.6.0 tiktoken-0.9.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "# Code cell 1\n",
    "\n",
    "! pip install openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken redis langchain langchain_openai langchain_community langchain-redis\n",
    "! pip install langchain-huggingface sentence-transformers scikit-learn\n",
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and set up Azure OpenAI and Azure Managed Redis connection info\n",
    "Fill in your Azure OpenAI and Azure Managed Redis information below. This will be used later to establish the connection these services, generate the embeddings, and load them into Redis. This example stores these values in application variables for the sake of simplicity. Outside of tutorials, it's strongly recommended to store these in environment variables or using a secrets manager like Azure KeyVault. \n",
    "\n",
    "Note that there are differences  between the `OpenAI` and `Azure OpenAI` endpoints. This example uses the configuration for `Azure OpenAI`. See [How to switch between OpenAI and Azure OpenAI endpoints with Python](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE_ENDPOINT: https://amrdemocbx.openai.azure.com\n",
      "REDIS_ENDPOINT: amrdemoscbx.australiaeast.redis.azure.net:10000\n",
      "DEPLOYMENT_NAME: text-embedding-3-large\n",
      "MODEL_NAME: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "# Code cell 2\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from num2words import num2words\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores.redis import Redis as RedisVectorStore\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "RESOURCE_ENDPOINT = os.getenv('RESOURCE_ENDPOINT')\n",
    "DEPLOYMENT_NAME = os.getenv('DEPLOYMENT_NAME')\n",
    "MODEL_NAME = os.getenv('MODEL_NAME')\n",
    "REDIS_ENDPOINT = os.getenv('REDIS_ENDPOINT')\n",
    "REDIS_PASSWORD = os.getenv('REDIS_PASSWORD')\n",
    "\n",
    "print(f\"RESOURCE_ENDPOINT: {RESOURCE_ENDPOINT}\")\n",
    "print(f\"REDIS_ENDPOINT: {REDIS_ENDPOINT}\")\n",
    "print(f\"DEPLOYMENT_NAME: {DEPLOYMENT_NAME}\")\n",
    "print(f\"MODEL_NAME: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset\n",
    "\n",
    "This example uses the [Wikipedia Movie Plots](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) dataset from Kaggle. Download this file and place it in the same directory as this jupyter notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34881</th>\n",
       "      <td>2014</td>\n",
       "      <td>The Water Diviner</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Director: Russell Crowe</td>\n",
       "      <td>Director: Russell Crowe\\r\\nCast: Russell Crowe...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Water_Diviner</td>\n",
       "      <td>The film begins in 1919, just after World War ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34882</th>\n",
       "      <td>2017</td>\n",
       "      <td>Çalgı Çengi İkimiz</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Selçuk Aydemir</td>\n",
       "      <td>Ahmet Kural, Murat Cemcir</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%C3%87alg%C4%B1_...</td>\n",
       "      <td>Two musicians, Salih and Gürkan, described the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34883</th>\n",
       "      <td>2017</td>\n",
       "      <td>Olanlar Oldu</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Hakan Algül</td>\n",
       "      <td>Ata Demirer, Tuvana Türkay, Ülkü Duru</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Olanlar_Oldu</td>\n",
       "      <td>Zafer, a sailor living with his mother Döndü i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884</th>\n",
       "      <td>2017</td>\n",
       "      <td>Non-Transferable</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Brendan Bradley</td>\n",
       "      <td>YouTubers Shanna Malcolm, Shira Lazar, Sara Fl...</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Non-Transferable...</td>\n",
       "      <td>The film centres around a young woman named Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34885</th>\n",
       "      <td>2017</td>\n",
       "      <td>İstanbul Kırmızısı</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Ferzan Özpetek</td>\n",
       "      <td>Halit Ergenç, Tuba Büyüküstün, Mehmet Günsür, ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%C4%B0stanbul_K%...</td>\n",
       "      <td>The writer Orhan Şahin returns to İstanbul aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34886 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                             Title Origin/Ethnicity  \\\n",
       "0              1901            Kansas Saloon Smashers         American   \n",
       "1              1901     Love by the Light of the Moon         American   \n",
       "2              1901           The Martyred Presidents         American   \n",
       "3              1901  Terrible Teddy, the Grizzly King         American   \n",
       "4              1902            Jack and the Beanstalk         American   \n",
       "...             ...                               ...              ...   \n",
       "34881          2014                 The Water Diviner          Turkish   \n",
       "34882          2017                Çalgı Çengi İkimiz          Turkish   \n",
       "34883          2017                      Olanlar Oldu          Turkish   \n",
       "34884          2017                  Non-Transferable          Turkish   \n",
       "34885          2017                İstanbul Kırmızısı          Turkish   \n",
       "\n",
       "                                 Director  \\\n",
       "0                                 Unknown   \n",
       "1                                 Unknown   \n",
       "2                                 Unknown   \n",
       "3                                 Unknown   \n",
       "4      George S. Fleming, Edwin S. Porter   \n",
       "...                                   ...   \n",
       "34881             Director: Russell Crowe   \n",
       "34882                      Selçuk Aydemir   \n",
       "34883                         Hakan Algül   \n",
       "34884                     Brendan Bradley   \n",
       "34885                      Ferzan Özpetek   \n",
       "\n",
       "                                                    Cast            Genre  \\\n",
       "0                                                    NaN          unknown   \n",
       "1                                                    NaN          unknown   \n",
       "2                                                    NaN          unknown   \n",
       "3                                                    NaN          unknown   \n",
       "4                                                    NaN          unknown   \n",
       "...                                                  ...              ...   \n",
       "34881  Director: Russell Crowe\\r\\nCast: Russell Crowe...          unknown   \n",
       "34882                          Ahmet Kural, Murat Cemcir           comedy   \n",
       "34883              Ata Demirer, Tuvana Türkay, Ülkü Duru           comedy   \n",
       "34884  YouTubers Shanna Malcolm, Shira Lazar, Sara Fl...  romantic comedy   \n",
       "34885  Halit Ergenç, Tuba Büyüküstün, Mehmet Günsür, ...         romantic   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "0      https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1      https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2      https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3      https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4      https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "...                                                  ...   \n",
       "34881    https://en.wikipedia.org/wiki/The_Water_Diviner   \n",
       "34882  https://en.wikipedia.org/wiki/%C3%87alg%C4%B1_...   \n",
       "34883         https://en.wikipedia.org/wiki/Olanlar_Oldu   \n",
       "34884  https://en.wikipedia.org/wiki/Non-Transferable...   \n",
       "34885  https://en.wikipedia.org/wiki/%C4%B0stanbul_K%...   \n",
       "\n",
       "                                                    Plot  \n",
       "0      A bartender is working at a saloon, serving dr...  \n",
       "1      The moon, painted with a smiling face hangs ov...  \n",
       "2      The film, just over a minute long, is composed...  \n",
       "3      Lasting just 61 seconds and consisting of two ...  \n",
       "4      The earliest known adaptation of the classic f...  \n",
       "...                                                  ...  \n",
       "34881  The film begins in 1919, just after World War ...  \n",
       "34882  Two musicians, Salih and Gürkan, described the...  \n",
       "34883  Zafer, a sailor living with his mother Döndü i...  \n",
       "34884  The film centres around a young woman named Am...  \n",
       "34885  The writer Orhan Şahin returns to İstanbul aft...  \n",
       "\n",
       "[34886 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell 3\n",
    "\n",
    "df=pd.read_csv(os.path.join(os.getcwd(),'wiki_movie_plots_deduped.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the dataset to remove spaces in the column titles and filter the dataset to lower the size. This isn't required, but is helpful in reducing the time it takes to generate embeddings and loading the index into Redis. Feel free to play around with the filters, or add your own! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>8626</td>\n",
       "      <td>$ aka Dollars</td>\n",
       "      <td>Richard Brooks</td>\n",
       "      <td>Warren Beatty, Goldie Hawn</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/$_(film)</td>\n",
       "      <td>Set in Hamburg, West Germany, several criminal...</td>\n",
       "      <td>1971</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8627</th>\n",
       "      <td>8627</td>\n",
       "      <td>200 Motels</td>\n",
       "      <td>Tony Palmer, Charles Swenson</td>\n",
       "      <td>Frank Zappa, Ringo Starr, Theodore Bikel</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/200_Motels</td>\n",
       "      <td>In 200 Motels, the film attempts to portray th...</td>\n",
       "      <td>1971</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>8628</td>\n",
       "      <td>The Anderson Tapes</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Sean Connery, Dyan Cannon, Christopher Walken,...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Anderson_Tapes</td>\n",
       "      <td>Burglar John \"Duke\" Anderson (Sean Connery) is...</td>\n",
       "      <td>1971</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>8629</td>\n",
       "      <td>The Andromeda Strain</td>\n",
       "      <td>Robert Wise</td>\n",
       "      <td>Arthur Hill, James Olson, Kate Reid, David Way...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Andromeda_St...</td>\n",
       "      <td>After a satellite, a U.S. government project c...</td>\n",
       "      <td>1971</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>8630</td>\n",
       "      <td>Bad Man's River</td>\n",
       "      <td>Eugenio Martin</td>\n",
       "      <td>Lee Van Cleef, Gina Lollobrigida</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bad_Man%27s_River</td>\n",
       "      <td>Roy King's gang robs a bank and flees to Mexic...</td>\n",
       "      <td>1971</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22428</th>\n",
       "      <td>22428</td>\n",
       "      <td>Hochelaga, Land of Souls (Hochelaga terre des ...</td>\n",
       "      <td>François Girard</td>\n",
       "      <td>Raoul Max Trujillo, Tanaya Beatty, David La Haye</td>\n",
       "      <td>historical drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hochelaga,_Land_...</td>\n",
       "      <td>One night on the campus of McGill University, ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>22429</td>\n",
       "      <td>Indian Horse</td>\n",
       "      <td>Stephen Campanelli</td>\n",
       "      <td>Forrest Goodluck, Michiel Huisman, Michael Mur...</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Indian_Horse_(film)</td>\n",
       "      <td>The Indian Horse family, including six-year-ol...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22430</th>\n",
       "      <td>22430</td>\n",
       "      <td>The Little Girl Who Was Too Fond of Matches (L...</td>\n",
       "      <td>Simon Lavoie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Little_Girl_...</td>\n",
       "      <td>In rural 1930s Quebec, Alice lives in house wi...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22431</th>\n",
       "      <td>22431</td>\n",
       "      <td>Meditation Park</td>\n",
       "      <td>Mina Shum</td>\n",
       "      <td>Sandra Oh, Liane Balaban, Don McKellar</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Meditation_Park</td>\n",
       "      <td>Opened by Mandarin theme song, Meditation Park...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22432</th>\n",
       "      <td>22432</td>\n",
       "      <td>Ravenous (Les Affamés)</td>\n",
       "      <td>Robin Aubert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>horror drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ravenous_(2017_f...</td>\n",
       "      <td>In the aftermath of a zombie-like outbreak, th...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11125 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              Title  \\\n",
       "8626    8626                                      $ aka Dollars   \n",
       "8627    8627                                         200 Motels   \n",
       "8628    8628                                 The Anderson Tapes   \n",
       "8629    8629                               The Andromeda Strain   \n",
       "8630    8630                                    Bad Man's River   \n",
       "...      ...                                                ...   \n",
       "22428  22428  Hochelaga, Land of Souls (Hochelaga terre des ...   \n",
       "22429  22429                                       Indian Horse   \n",
       "22430  22430  The Little Girl Who Was Too Fond of Matches (L...   \n",
       "22431  22431                                    Meditation Park   \n",
       "22432  22432                             Ravenous (Les Affamés)   \n",
       "\n",
       "                           Director  \\\n",
       "8626                 Richard Brooks   \n",
       "8627   Tony Palmer, Charles Swenson   \n",
       "8628                   Sidney Lumet   \n",
       "8629                    Robert Wise   \n",
       "8630                 Eugenio Martin   \n",
       "...                             ...   \n",
       "22428               François Girard   \n",
       "22429            Stephen Campanelli   \n",
       "22430                  Simon Lavoie   \n",
       "22431                     Mina Shum   \n",
       "22432                  Robin Aubert   \n",
       "\n",
       "                                                    Cast             Genre  \\\n",
       "8626                          Warren Beatty, Goldie Hawn           unknown   \n",
       "8627            Frank Zappa, Ringo Starr, Theodore Bikel           unknown   \n",
       "8628   Sean Connery, Dyan Cannon, Christopher Walken,...           unknown   \n",
       "8629   Arthur Hill, James Olson, Kate Reid, David Way...           unknown   \n",
       "8630                    Lee Van Cleef, Gina Lollobrigida           unknown   \n",
       "...                                                  ...               ...   \n",
       "22428   Raoul Max Trujillo, Tanaya Beatty, David La Haye  historical drama   \n",
       "22429  Forrest Goodluck, Michiel Huisman, Michael Mur...             drama   \n",
       "22430                                                NaN           unknown   \n",
       "22431             Sandra Oh, Liane Balaban, Don McKellar             drama   \n",
       "22432                                                NaN      horror drama   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "8626              https://en.wikipedia.org/wiki/$_(film)   \n",
       "8627            https://en.wikipedia.org/wiki/200_Motels   \n",
       "8628    https://en.wikipedia.org/wiki/The_Anderson_Tapes   \n",
       "8629   https://en.wikipedia.org/wiki/The_Andromeda_St...   \n",
       "8630     https://en.wikipedia.org/wiki/Bad_Man%27s_River   \n",
       "...                                                  ...   \n",
       "22428  https://en.wikipedia.org/wiki/Hochelaga,_Land_...   \n",
       "22429  https://en.wikipedia.org/wiki/Indian_Horse_(film)   \n",
       "22430  https://en.wikipedia.org/wiki/The_Little_Girl_...   \n",
       "22431      https://en.wikipedia.org/wiki/Meditation_Park   \n",
       "22432  https://en.wikipedia.org/wiki/Ravenous_(2017_f...   \n",
       "\n",
       "                                                    Plot  year    origin  \n",
       "8626   Set in Hamburg, West Germany, several criminal...  1971  American  \n",
       "8627   In 200 Motels, the film attempts to portray th...  1971  American  \n",
       "8628   Burglar John \"Duke\" Anderson (Sean Connery) is...  1971  American  \n",
       "8629   After a satellite, a U.S. government project c...  1971  American  \n",
       "8630   Roy King's gang robs a bank and flees to Mexic...  1971  American  \n",
       "...                                                  ...   ...       ...  \n",
       "22428  One night on the campus of McGill University, ...  2017  Canadian  \n",
       "22429  The Indian Horse family, including six-year-ol...  2017  Canadian  \n",
       "22430  In rural 1930s Quebec, Alice lives in house wi...  2017  Canadian  \n",
       "22431  Opened by Mandarin theme song, Meditation Park...  2017  Canadian  \n",
       "22432  In the aftermath of a zombie-like outbreak, th...  2017  Canadian  \n",
       "\n",
       "[11125 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell 4\n",
    "\n",
    "df.insert(0, 'id', range(0, len(df)))\n",
    "df['year'] = df['Release Year'].astype(int)\n",
    "df['origin'] = df['Origin/Ethnicity'].astype(str)\n",
    "del df['Release Year']\n",
    "del df['Origin/Ethnicity']\n",
    "df = df[df.year > 1970] # only movies made after 1970\n",
    "df = df[df.origin.isin(['American','British','Canadian'])] # only movies from English-speaking cinema\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove whitespace from the `Plot` column to make it easier to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell 5\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df['Plot']= df['Plot'].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of tokens required to generate the embeddings for this dataset. You may want to filter the dataset more stringently in order to limit the tokens required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 11125\n",
      "Number of tokens required:7044844\n"
     ]
    }
   ],
   "source": [
    "# Code cell 6\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df[\"Plot\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df = df[df.n_tokens<8192]\n",
    "print('Number of movies: ' + str(len(df))) # print number of movies remaining in dataset\n",
    "print('Number of tokens required:' + str(df['n_tokens'].sum())) # print number of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataframe into LangChain\n",
    "Using the `DataFrameLoader` class allows you to load a pandas dataframe into LangChain. That makes it easy to load your data and use it to generate embeddings using LangChain's other integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell 7\n",
    "\n",
    "loader = DataFrameLoader(df, page_content_column=\"Plot\" )\n",
    "movie_list = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embeddings and Load them into Azure Managed Redis\n",
    "Using LangChain, this example connects to Azure OpenAI Service to generate embeddings for the dataset. These embeddings are then loaded into [Azure Managed Redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/managed-redis/managed-redis-overview), a fully managed Redis service on Azure, which features the [RediSearch](https://redis.io/docs/latest/develop/interact/search-and-query/) module that includes vector search capability. Finally, a copy of the index schema is saved. That is useful for loading the index into Redis later if you don't want to regenerate the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [10:51<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Code cell 8\n",
    "\n",
    "# we will use Azure OpenAI as our embeddings provider\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=RESOURCE_ENDPOINT,\n",
    "    azure_deployment=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_version='2024-03-01-preview',\n",
    "    show_progress_bar=True,\n",
    "    chunk_size=16)\n",
    "\n",
    "# name of the Redis search index to create\n",
    "index_name = \"movieindex\"\n",
    "\n",
    "# create a connection string for the Redis Vector Store. Uses Redis-py format: https://redis-py.readthedocs.io/en/stable/connections.html#redis.Redis.from_url\n",
    "# This example assumes TLS is enabled. If not, use \"redis://\" instead of \"rediss://\n",
    "redis_url = \"rediss://:\" + REDIS_PASSWORD + \"@\"+ REDIS_ENDPOINT\n",
    "\n",
    "# Take the first 100 movies\n",
    "# short_list = movie_list[:100]\n",
    "\n",
    "# create and load redis with documents\n",
    "vectorstore = RedisVectorStore.from_documents(\n",
    "    documents=movie_list,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name,\n",
    "    redis_url=redis_url\n",
    ")\n",
    "\n",
    "# save index schema so you can reload in the future without re-generating embeddings\n",
    "vectorstore.write_schema(\"redis_schema.yaml\")\n",
    "\n",
    "# This may take up to 10 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run search queries\n",
    "Using the vectorstore we just built in LangChain, we can conduct similarity searches using the `similarity_search_with_score` method. In this example, the top 10 results for a given query are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Code cell 9\n",
    "\n",
    "results = vectorstore.similarity_search_with_score(query=\"Spaceships, aliens, and heroes saving America\", k=10)\n",
    "\n",
    "for doc, score  in enumerate(results):\n",
    "    movie_title = str(results[doc][0].metadata['Title'])\n",
    "    similarity_score = str(round((1 - results[doc][1]),4))\n",
    "    print(movie_title + ' (Score: ' + similarity_score + ')')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hybrid queries\n",
    "\n",
    "You can also run hybrid queries. That is, queries that use both vector search and filters based on other parameters in the dataset. In this case, we filter our query results to only movies tagged with the `comedy` genre. One of the advantages of using LangChain with Redis is that metadata is preserved in the index, so you can use it to filter your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Men (Score: 0.4859)\n",
      "Real Men (Score: 0.4857)\n",
      "Mars Attacks! (Score: 0.479)\n",
      "Alien Trespass (Score: 0.4771)\n",
      "Meet Dave (Score: 0.4693)\n",
      "Strange Invaders (Score: 0.4642)\n",
      "Strange Invaders (Score: 0.4642)\n",
      "My Science Project (Score: 0.455)\n",
      "My Science Project (Score: 0.455)\n",
      "Galaxy Quest (Score: 0.4544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Code cell 10\n",
    "\n",
    "from langchain.vectorstores.redis import RedisText\n",
    "\n",
    "query = \"Spaceships, aliens, and heroes saving America\"\n",
    "genre = \"comedy\"\n",
    "\n",
    "genre_filter = RedisText(\"Genre\") == genre\n",
    "\n",
    "results = vectorstore.similarity_search_with_score(query, filter=genre_filter, k=10)\n",
    "for i, j in enumerate(results):\n",
    "    movie_title = str(results[i][0].metadata['Title'])\n",
    "    similarity_score = str(round((1 - results[i][1]),4))\n",
    "    print(movie_title + ' (Score: ' + similarity_score + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A: Load index data already in Redis\n",
    "If you already have embeddings data in Redis, you can load it into your LangChain vectorstore oboject using the `from_existing_index` method. This is useful if you don't want to re-run your embeddings model. You'll need to provide the index schema that was saved when you generated the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94659/3029146387.py:4: LangChainDeprecationWarning: The class `AzureOpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureOpenAIEmbeddings``.\n",
      "  embedding = AzureOpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Code cell 11\n",
    "\n",
    "# we will use Azure OpenAI as our embeddings provider\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=RESOURCE_ENDPOINT,\n",
    "    azure_deployment=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_version='2024-03-01-preview',\n",
    "    show_progress_bar=True,\n",
    "    chunk_size=16)\n",
    "\n",
    "# name of the Redis search index to create\n",
    "index_name = \"movieindex\"\n",
    "\n",
    "# create a connection string for the Redis Vector Store. Uses Redis-py format: https://redis-py.readthedocs.io/en/stable/connections.html#redis.Redis.from_url\n",
    "# This example assumes TLS is enabled. If not, use \"redis://\" instead of \"rediss://\n",
    "redis_url = \"rediss://:\" + REDIS_PASSWORD + \"@\"+ REDIS_ENDPOINT\n",
    "\n",
    "vectorstore = RedisVectorStore.from_existing_index(\n",
    "    embedding=embedding,\n",
    "    redis_url=redis_url,\n",
    "    index_name=index_name,\n",
    "    schema=\"redis_schema.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix B: Query Redis using the CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redisvl in ./.venv/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: coloredlogs<16.0,>=15.0 in ./.venv/lib/python3.11/site-packages (from redisvl) (15.0.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from redisvl) (0.4.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from redisvl) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=2 in ./.venv/lib/python3.11/site-packages (from redisvl) (2.10.6)\n",
      "Requirement already satisfied: python-ulid<4.0.0,>=3.0.0 in ./.venv/lib/python3.11/site-packages (from redisvl) (3.0.0)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.4 in ./.venv/lib/python3.11/site-packages (from redisvl) (6.0.2)\n",
      "Requirement already satisfied: redis<6.0,>=5.0 in ./.venv/lib/python3.11/site-packages (from redisvl) (5.2.1)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in ./.venv/lib/python3.11/site-packages (from redisvl) (0.9.0)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in ./.venv/lib/python3.11/site-packages (from redisvl) (9.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.11/site-packages (from coloredlogs<16.0,>=15.0->redisvl) (10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "# Install RedisVL\n",
    "! pip install redisvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:06:43\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Indices:\n",
      "\u001b[32m14:06:43\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   1. movieindex\n",
      "\n",
      "\n",
      "Index Information:\n",
      "╭──────────────┬────────────────┬────────────────────┬─────────────────┬────────────╮\n",
      "│ Index Name   │ Storage Type   │ Prefixes           │ Index Options   │   Indexing │\n",
      "├──────────────┼────────────────┼────────────────────┼─────────────────┼────────────┤\n",
      "│ movieindex   │ HASH           │ ['doc:movieindex'] │ []              │          0 │\n",
      "╰──────────────┴────────────────┴────────────────────┴─────────────────┴────────────╯\n",
      "Index Fields:\n",
      "╭────────────────┬────────────────┬─────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬─────────────────┬────────────────╮\n",
      "│ Name           │ Attribute      │ Type    │ Field Option   │ Option Value   │ Field Option   │ Option Value   │ Field Option   │   Option Value │ Field Option    │ Option Value   │\n",
      "├────────────────┼────────────────┼─────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼─────────────────┼────────────────┤\n",
      "│ Title          │ Title          │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ Director       │ Director       │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ Cast           │ Cast           │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ Genre          │ Genre          │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ Wiki Page      │ Wiki Page      │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ origin         │ origin         │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ content        │ content        │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ id             │ id             │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ year           │ year           │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ n_tokens       │ n_tokens       │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
      "│ content_vector │ content_vector │ VECTOR  │ algorithm      │ FLAT           │ data_type      │ FLOAT32        │ dim            │           3072 │ distance_metric │ COSINE         │\n",
      "╰────────────────┴────────────────┴─────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴─────────────────┴────────────────╯\n",
      "\n",
      "Statistics:\n",
      "╭─────────────────────────────┬────────────────────╮\n",
      "│ Stat Key                    │ Value              │\n",
      "├─────────────────────────────┼────────────────────┤\n",
      "│ num_docs                    │ 11125              │\n",
      "│ num_terms                   │ 181967             │\n",
      "│ max_doc_id                  │ 5661               │\n",
      "│ num_records                 │ 3822361            │\n",
      "│ percent_indexed             │ 1                  │\n",
      "│ hash_indexing_failures      │ 0                  │\n",
      "│ number_of_uses              │ 21                 │\n",
      "│ bytes_per_record_avg        │ 12.752371311187744 │\n",
      "│ doc_table_size_mb           │ 1.220107078552246  │\n",
      "│ inverted_sz_mb              │ 46.482330322265625 │\n",
      "│ key_table_size_mb           │ 0.4202690124511719 │\n",
      "│ offset_bits_per_record_avg  │ 11.759797096252441 │\n",
      "│ offset_vectors_sz_mb        │ 8.113744735717773  │\n",
      "│ offsets_per_term_avg        │ 1.5141814947128296 │\n",
      "│ records_per_doc_avg         │ 343.5764923095703  │\n",
      "│ sortable_values_size_mb     │ 0                  │\n",
      "│ total_indexing_time         │ None               │\n",
      "│ total_inverted_index_blocks │ 204915             │\n",
      "│ vector_index_sz_mb          │ 144.53318786621094 │\n",
      "╰─────────────────────────────┴────────────────────╯\n"
     ]
    }
   ],
   "source": [
    "# Query Azure Manager Redis\n",
    "! rvl index listall -u $redis_url\n",
    "! rvl index info -i movieindex -u $redis_url\n",
    "! rvl stats -i movieindex -u $redis_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m07:53:54\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Index deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# Destroy movie index\n",
    "! rvl index destroy -i movieindex -u $redis_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix C: Simple RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clarence/dev/demos/azure-cache-redis-samples/tutorial/vector-similarity-search-open-ai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Tom Cruise stars in several movies within the provided context, primarily featuring the character Ethan Hunt in the \"Mission: Impossible\" series. In these films, Hunt is an IMF agent who undertakes dangerous missions involving espionage, high-stakes heists, and complex plots against various antagonists.\n",
      "\n",
      "Additionally, Cruise plays David Aames in \"Vanilla Sky,\" where he navigates a mentally complex and surreal storyline involving love, loss, and dreams. Another noteworthy performance is as Lieutenant Pete \"Maverick\" Mitchell in \"Top Gun,\" where he is a naval aviator who deals with personal loss and seeks to prove himself among the best pilots.\n",
      "\n",
      "If you are looking for specific movies or details about a particular role, let me know!\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"RESOURCE_ENDPOINT\"),\n",
    "    azure_deployment='gpt-4o-mini',\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    openai_api_version=\"2024-09-01-preview\"\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"You are a movie buff who can answer questions about movies, make suggestions, summarise key facts, and provide other useful movie information. Use the following information as context to build your answer. If you are unsure, just say 'I'm unsure\".  Only discuss movies from the context provided.  Don't discuss other topics not related to the movies.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "while True:\n",
    "    question = input(\"What's your question about movie(s)? \")\n",
    "    if question == 'q' or question == '':\n",
    "        print('Bye!')\n",
    "        break\n",
    "    else:\n",
    "        answer = rag_chain.invoke(question)\n",
    "\n",
    "        print(f'\\nAnswer:\\n{answer}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
